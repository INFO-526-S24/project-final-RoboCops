---
title: "Project Title"
subtitle: "INFO 526 - Final Project"
author: 
  - name: "RoboCops - Peter, Sachin, Arun, Surajit, Christian, Valerie"
    affiliations:
      - name: "School of Information, University of Arizona"
description: "This project aims to comprehensively analyze fatal police shootings in the United States, delving into the underlying factors and motivations driving these tragic events."
format:
   html:
    code-tools: true
    code-overflow: wrap
    embed-resources: true
editor: visual
execute:
  warning: false
  echo: false
---

```{r}
#| label: load-packages
#| include: false

# Load packages here
pacman::p_load(dplyr,
               ggplot2,
               ggridges,
               scales,
               patchwork,
               stringr,
               grep,
               kableExtra,
               plotly,
               maps,
               ggrepel,
               animation, 
               RColorBrewer)

```

```{r}
#| label: load-dataset
#| message: false

# Load in the datasets
fatality <- read.csv("data/PoliceKillingsUS.csv", na.strings = "")
median_income <- read.csv("data/MedianHouseholdIncome2015.csv")
poverty_perc <- read.csv("data/PercentagePeopleBelowPovertyLevel.csv")
hs_perc <- read.csv("data/PercentOver25CompletedHighSchool.csv")
race_perc <- read.csv("data/ShareRaceByCity.csv")
city_pop <- read.csv("data/us-cities-top-1k-multi-year.csv")
state_pop <- read.csv("data/Population_Estimate_data_Statewise_2010-2023.csv")
```

```{r}
#| label: data-setup
#| message: false

# Recode Fatality NA
fatality <- fatality |>
  mutate(
    race = case_when(
      race %in% "A" ~ "Asian",
      race %in% "B" ~ "Black",
      race %in% "H" ~ "Hispanic",
      race %in% "N" ~ "Native American",
      race %in% "O" ~ "Other",
      race %in% "W" ~ "White",
      is.na(race) == TRUE ~ "Unknown",
      TRUE ~ race
    )
  )

# Recode non-numeric values as "", remove NA
median_income <- median_income |>
  mutate(
    Median.Income = case_when(
      Median.Income %in% "-" ~ "",
      Median.Income %in% "(X)" ~ "",
      TRUE ~ Median.Income
    )
  )
median_income$Median.Income <- as.numeric(median_income$Median.Income)
median_income <- na.omit(median_income)

# Clean race data
race_perc[,3] <- as.numeric(race_perc[,3])
race_perc[,4] <- as.numeric(race_perc[,4])
race_perc[,5] <- as.numeric(race_perc[,5])
race_perc[,6] <- as.numeric(race_perc[,6])
race_perc[,7] <- as.numeric(race_perc[,7])
colnames(race_perc) <- c("Geographic.Area", "City",
                         "White", "Black", "Native", "Asian", "Hispanic")

# Adjust the state abbreviations to full name
state_pop <- state_pop |>
  mutate(
    STATE = case_when(
      STATE %in% "Alabama" ~ "AL",
      STATE %in% "Alaska" ~ "AK",
      STATE %in% "Arizona" ~ "AZ",
      STATE %in% "Arkansas" ~ "AR",
      STATE %in% "California" ~ "CA",
      STATE %in% "Colorado" ~ "CO",
      STATE %in% "Connecticut" ~ "CT",
      STATE %in% "Delaware" ~ "DE",
      STATE %in% "District of Columbia" ~ "DC",
      STATE %in% "Florida" ~ "FL",
      STATE %in% "Georgia" ~ "GA",
      STATE %in% "Hawaii" ~ "HI",
      STATE %in% "Idaho" ~ "ID",
      STATE %in% "Illinois" ~ "IL",
      STATE %in% "Indiana" ~ "IN",
      STATE %in% "Iowa" ~ "IA",
      STATE %in% "Kansas" ~ "KS",
      STATE %in% "Kentucky" ~ "KY",
      STATE %in% "Louisiana" ~ "LA",
      STATE %in% "Maine" ~ "ME",
      STATE %in% "Maryland" ~ "MD",
      STATE %in% "Massachusetts" ~ "MA",
      STATE %in% "Michigan" ~ "MI",
      STATE %in% "Minnesota" ~ "MN",
      STATE %in% "Mississipi" ~ "MS",
      STATE %in% "Missouri" ~ "MO",
      STATE %in% "Montana" ~ "MT",
      STATE %in% "Nebraska" ~ "NE",
      STATE %in% "Nevada" ~ "NV",
      STATE %in% "New Hampshire" ~ "NH",
      STATE %in% "New Jersey" ~ "NJ",
      STATE %in% "New Mexico" ~ "NM",
      STATE %in% "New York" ~ "NY",
      STATE %in% "North Carolina" ~ "NC",
      STATE %in% "North Dakota" ~ "ND",
      STATE %in% "Ohio" ~ "OH",
      STATE %in% "Oklahoma" ~ "OK",
      STATE %in% "Oregon" ~ "OR",
      STATE %in% "Pennsylvania" ~ "PA",
      STATE %in% "Puerto Rico" ~ "PR",
      STATE %in% "Rhode Island" ~ "RI",
      STATE %in% "South Carolina" ~ "SC",
      STATE %in% "South Dakota" ~ "SD",
      STATE %in% "Tennessee" ~ "TN",
      STATE %in% "Texas" ~ "TX",
      STATE %in% "Utah" ~ "UT",
      STATE %in% "Vermont" ~ "VT",
      STATE %in% "Virginia" ~ "VA",
      STATE %in% "Washington" ~ "WA",
      STATE %in% "West Virginia" ~ "WV",
      STATE %in% "Wisconsin" ~ "WI",
      STATE %in% "Wyoming" ~ "WY"
    )
  )

# Change colnames for easier matching
colnames(state_pop) <- c("State", colnames(state_pop[-1]))

# Select State and 2015 column
state_pop <- state_pop[, c("State", "POPESTIMATE2015")]

# City population modify state
city_pop <- city_pop |>
  mutate(
    State = case_when(
      State %in% "Alabama" ~ "AL",
      State %in% "Alaska" ~ "AK",
      State %in% "Arizona" ~ "AZ",
      State %in% "Arkansas" ~ "AR",
      State %in% "California" ~ "CA",
      State %in% "Colorado" ~ "CO",
      State %in% "Connecticut" ~ "CT",
      State %in% "Delaware" ~ "DE",
      State %in% "District of Columbia" ~ "DC",
      State %in% "Florida" ~ "FL",
      State %in% "Georgia" ~ "GA",
      State %in% "Hawaii" ~ "HI",
      State %in% "Idaho" ~ "ID",
      State %in% "Illinois" ~ "IL",
      State %in% "Indiana" ~ "IN",
      State %in% "Iowa" ~ "IA",
      State %in% "Kansas" ~ "KS",
      State %in% "Kentucky" ~ "KY",
      State %in% "Louisiana" ~ "LA",
      State %in% "Maine" ~ "ME",
      State %in% "Maryland" ~ "MD",
      State %in% "Massachusetts" ~ "MA",
      State %in% "Michigan" ~ "MI",
      State %in% "Minnesota" ~ "MN",
      State %in% "Mississipi" ~ "MS",
      State %in% "Missouri" ~ "MO",
      State %in% "Montana" ~ "MT",
      State %in% "Nebraska" ~ "NE",
      State %in% "Nevada" ~ "NV",
      State %in% "New Hampshire" ~ "NH",
      State %in% "New Jersey" ~ "NJ",
      State %in% "New Mexico" ~ "NM",
      State %in% "New York" ~ "NY",
      State %in% "North Carolina" ~ "NC",
      State %in% "North Dakota" ~ "ND",
      State %in% "Ohio" ~ "OH",
      State %in% "Oklahoma" ~ "OK",
      State %in% "Oregon" ~ "OR",
      State %in% "Pennsylvania" ~ "PA",
      State %in% "Puerto Rico" ~ "PR",
      State %in% "Rhode Island" ~ "RI",
      State %in% "South Carolina" ~ "SC",
      State %in% "South Dakota" ~ "SD",
      State %in% "Tennessee" ~ "TN",
      State %in% "Texas" ~ "TX",
      State %in% "Utah" ~ "UT",
      State %in% "Vermont" ~ "VT",
      State %in% "Virginia" ~ "VA",
      State %in% "Washington" ~ "WA",
      State %in% "West Virginia" ~ "WV",
      State %in% "Wisconsin" ~ "WI",
      State %in% "Wyoming" ~ "WY"
    )
  )

# Filter city population by 2015
city_pop <- city_pop[which(city_pop$year == 2015),]

# Concatenate supplementary datasets
supp_data <- left_join(hs_perc, median_income,
                       by = c("Geographic.Area" , "City"))

supp_data <- left_join(supp_data, poverty_perc,
                       by = c("Geographic.Area" , "City"))

supp_data <- left_join(supp_data, race_perc)
colnames(supp_data) <- c("State",
                         "City",
                         "HSDegree",
                         "Median",
                         "Poverty",
                         "White",
                         "Black",
                         "Native",
                         "Asian",
                         "Hispanic")

supp_data$City <- iconv(supp_data$City, to = "UTF-8")

# Remove " city" from the Location column
supp_data$City <- gsub(" city", "", supp_data$City)
supp_data$City <- gsub(" town", "", supp_data$City)
supp_data$City <- gsub(" CDP", "", supp_data$City)

# Merge supplementary data and state population data
supp_data <- left_join(supp_data, city_pop,
                       by = c("State", "City"))

# # First, explicitly convert the encoding of city names to UTF-8

# 
# # Define a function to safely apply gsub and catch errors
# safe_gsub <- function(pattern, replacement, x) {
#   tryCatch({
#     gsub(pattern, replacement, x, perl = TRUE)
#   }, error = function(e) {
#     message("Error with input: ", x)
#     x # Return original string on error
#   })
# }
# 
# #safe_gsub
# 
# # Apply the safe_gsub function to remove " city", " town", and " CDP"
# supp_data$City <- sapply(supp_data$City, function(x) safe_gsub(" city", "", x))
# supp_data$City <- sapply(supp_data$City, function(x) safe_gsub(" town", "", x))
# supp_data$City <- sapply(supp_data$City, function(x) safe_gsub(" CDP", "", x))
# 
# # Merge supplementary data and state population data
# supp_data <- left_join(supp_data, city_pop,
#                        by = c("State", "City"))


```

## Abstract

The objective of this project is to analyze and contextualize police shootings, aiming to understand the underlying reasons and factors contributing to these unfortunate events. Acknowledging the necessity of police interventions for public safety, there has been a concerning uptick of documented unjustified shootings in recent years. We seek to expand the analysis beyond individual cases to explore socioeconomic factors like housing income, poverty rates and population demographics, and uncover correlations and patterns that shed light on the broader societal context.

This will be achieved through the use of data visualizations to contribute to a deeper understanding of police shootings.

## Introduction

\*Introduction: The introduction provides a clear explanation of the question and the dataset used to answer the question, including a description of all relevant variables in the dataset. (3 points)

Police shootings are a sad reality of policing practices that date back decades. While many are justified to protect the lives of innocent civilians, there has been an uptick in recent years of police shooting people whom they perceive to be a threat in the heat of the moment, but are proven innocent after the fact. These shootings can often be hard to analyze because there are many psychological factors that come into play when an officer decides to discharge their weapon, such as their training, the perceived threat, and an officer's internalized prejudice. Without further information on the psyche of a police officer, the reason why they discharge their weapon cannot be determined. However, their actions and surroundings can be analyzed to provide context into communities and situations that may be more prone to police shootings.

The police shooting data set is sourced from a Kaggle dataset originally created by Karolina Wullum. The dataset consists of shootings from all fifty states and DC, and is supplemented with informations on demographics including as median household income, distribution of race, city population, percent of people below poverty line, and percent of people over 25 who completed high school.

This analysis aims to understand the dataset on police killings, extending its scope beyond the original focus tracked by the Washington Post. Socioeconomic factors like housing income, poverty rates, and population demographics will be used to understand and contextualize any patterns that appear. The goal is to explore how socioeconomic factors can play into incidents of police violence. The following table represents the variables relevant to the analysis.

```{r}
#| label: dataset-table
#| echo: false
#| message: false

# Create columns for data
fatality_var <- colnames(fatality)

fatality_desc <- c("Data ID",
                   "Name of deceased",
                   "Date of shooting",
                   "Means of death",
                   "Weapon/Tool",
                   "Age of deceased",
                   "Gender of deceased",
                   "Race of deceased",
                   "City",
                   "State",
                   "Sign of mental illness during incident",
                   "Deceased's threat level",
                   "Method to evade police",
                   "Reports of police with body camera")

fatality_type <- c("numeric",
                   "character",
                   "date",
                   "categorical",
                   "categorical",
                   "numeric",
                   "logical",
                   "categorical",
                   "categorical",
                   "categorical",
                   "logical",
                   "categorical",
                   "categorical",
                   "logical")

fatality_values <- c("2535 entries",
                     "Names",
                     "dd/mm/yy from 2015-2017",
                     "shot, shot and tasered",
                     "69 categories",
                     "6-91 years old",
                     "F/M",
                     "A, B, H, N, O, W, Unknown",
                     "1417 cities",
                     "State 2 letter abbreviations and DC",
                     "True/False",
                     "attack, other, undetermined",
                     "Car, Foot, Not fleeing, Other",
                     "True/False")

# Bind the vectors into a dataframe
fatality_table <- as.data.frame(cbind(fatality_var,
                                      fatality_desc,
                                      fatality_type,
                                     fatality_values))
colnames(fatality_table) <- c("Variable", "Description", "Data Type", "Values")
row.names(fatality_table) <- seq(1:14)

# Generate a nice table with kable
my_table <- kable(fatality_table, "html") %>%
  kable_styling(full_width = FALSE)

# Display the table
my_table

```

Additionally, six .csv files are utilized to provide supplemental demographic data such as poverty levels, percent high school graduates, city and state population, race percentage by city, and median household income.

```{r}

#| label: census-table
#| echo: false
#| message: false

# Create columns for data
census_data <- c("PercentOver25CompletedHighSchool.csv",
                 "MedianHouseholdIncome2015.csv",
                 "PercentagePeopleBelowPovertyLevel.csv",
                 "ShareRaceByCity.csv", 
                 "Population_Estimate_data_Statewise_2010-2023.csv", 
                 "us-cities-top-1k-multi-year.csv")

census_desc <- c("Contains the percentage of individuals 25 years and older that are highschool graduates for cities",
                 "Contains the median income for cities",
                 "Contains the percentage of the population below poverty for cities",
                 "Contains the demographics for cities", 
                 "Contains state populations", 
                 "Contains populations of the top 1000 largest cities in the US")

census_n <- c(nrow(hs_perc),
              nrow(median_income),
              nrow(poverty_perc),
              nrow(race_perc), 
              nrow(state_pop), 
              nrow(city_pop))

# Bind the vectors into a dataframe
census_table <- as.data.frame(cbind(census_data, census_desc, census_n))
colnames(census_table) <- c("Data", "Description", "Number of Rows")
row.names(census_table) <- seq(1:6)

# Generate a nice table with kable
my_table <- kable(census_table, "html") %>%
  kable_styling(full_width = FALSE)

my_table

```

By incorporating these additional factors, correlations and patterns can be uncovered that provide insight into the broader societal context surrounding police use of force. Through data visualization and analysis, contributions to a deeper understanding of these issues and support evidence-based policy-making for promoting equity and justice.

## Question 1

1.  How do socioeconomic factors such as median income, poverty rates, and educational relate with incidents of police use of force across different geographic areas?

### Description of Analysis

For the bar plot which illustrates the socio-economic backdrop of fatal police encounters is classified meticulously by poverty and education levels. The underlying data, standardized for consistency, undergoes a transformation to quantify both poverty rates and high school completion rates, subsequently binned into quintiles for a granular analysis. The methodology ensures that each bracket spans an equal range of the data, capturing a full spectrum of socio-economic statuses. These brackets are then labeled with intuitive percentage ranges, setting the stage for the ensuing visual assessment. This careful numerical and categorical preparation underpins the creation of two bar charts, which, through the nuanced lens of ggplot2, lay bare the stark contrasts in threat level distributions across different socio-economic strata, painting a telling picture of the intersection between socio-economic factors and lethal police interventions.

For the density ridge plots, the population for each race was calculated from the supplemental datasets by multiplying the 2015 city population estimate with the estimated racial proportion of the city and divided by 100. The police shooting dataset, median income dataset, and the cities race estimates were concatenated according to city and state. The merged data was then subsetted to only include incidents with a median income and race estimates. The first ridge plot, which is organized by the total count of fatalities by race, refactorized the race levels according to the total counts and used a geom_density_ridge() with the median income as the horizontal axis and the race as the vertical axis.

The second density ridge plot, which is organized by the race's relative proportion of fatalities (ie the number of fatalities divided by the estimated race's total population). The race's population estimate was calculated by summing the estimated race's population for all cities included in the subsetted data. The data race levels were refactorized according to the proportions with Other and Unknown set to the bottom of the plot. Other and Unknown were set to the bottom of the plot since the interest of this analysis is focused on the potential difference in incidence when race is considered.

### Plot 1

```{r}
#| label: Q1-plot1
#| fig-width: 9
#| fig-asp: 0.8

#glimpse(fatality)
#glimpse(median_income)
#glimpse(poverty_perc)
#glimpse(hs_perc)
#glimpse(race_perc)
#glimpse(city_pop)
#glimpse(state_pop)


#supp_data

supp_data <- na.omit(supp_data)

#glimpse(supp_data)


# Ensure the column names are correctly formatted before merging
fatality$city <- as.character(fatality$city)
fatality$state <- as.character(fatality$state)
supp_data$City <- as.character(supp_data$City)
supp_data$State <- as.character(supp_data$State)

# Merge the main fatality data with the supplementary socio-economic data
analysis_data <- merge(fatality, supp_data, by.x = c("city", "state"), by.y = c("City", "State"))

# Convert Poverty from character to numeric to handle in quantile calculation
analysis_data$Poverty <- as.numeric(as.character(analysis_data$Poverty))

# Check for NA in Poverty which might disrupt quantile calculation
if (any(is.na(analysis_data$Poverty))) {
  analysis_data$Poverty[is.na(analysis_data$Poverty)] <- median(analysis_data$Poverty, na.rm = TRUE)
}

#glimpse(analysis_data)

# Ensure Poverty is numeric
analysis_data$Poverty <- as.numeric(as.character(analysis_data$Poverty))

# Convert HSDegree to numeric, coercing non-numeric values to NA
analysis_data$HSDegree <- as.numeric(as.character(analysis_data$HSDegree))

# Calculate the range for Poverty and HSDegree
range_poverty <- max(analysis_data$Poverty, na.rm = TRUE) - min(analysis_data$Poverty, na.rm = TRUE)
range_hsdegree <- max(analysis_data$HSDegree, na.rm = TRUE) - min(analysis_data$HSDegree, na.rm = TRUE)

# Define consistent breaks based on the range
number_of_brackets <- 5 # For example, 5 equal brackets
breaks_poverty <- seq(min(analysis_data$Poverty, na.rm = TRUE), 
                      max(analysis_data$Poverty, na.rm = TRUE), 
                      length.out = number_of_brackets + 1)

breaks_hsdegree <- seq(min(analysis_data$HSDegree, na.rm = TRUE), 
                       max(analysis_data$HSDegree, na.rm = TRUE), 
                       length.out = number_of_brackets + 1)

# Function to create labels based on breaks
create_labels <- function(breaks) {
  labels <- c()
  for (i in 1:(length(breaks) - 1)) {
    labels <- c(labels, paste(formatC(breaks[i], format = "f", digits = 0), "-", formatC(breaks[i+1], format = "f", digits = 0), "%"))
  }
  return(labels)
}

# Use these breaks to make the cuts consistent
analysis_data$poverty_bracket <- cut(analysis_data$Poverty,
                                     breaks = breaks_poverty,
                                     include.lowest = TRUE,
                                     labels = create_labels(breaks_poverty))

analysis_data$edu_bracket <- cut(analysis_data$HSDegree,
                                 breaks = breaks_hsdegree,
                                 include.lowest = TRUE,
                                 labels = create_labels(breaks_hsdegree))

analysis_data$threat_level <- str_to_title(analysis_data$threat_level)

# Plotting for Poverty Bracket
poverty_plot  <- ggplot(analysis_data, aes(x = poverty_bracket, fill = threat_level)) +
  geom_bar(position = "identity", width = 0.5) +
  scale_fill_brewer(palette = 'Set3') + 
  #guides(fill = "none") + # This removes the legend from this plot
  theme_minimal() +
  labs(title = "Distribution of Threat Levels by Poverty Bracket",
       x = "Percentage of Population in Poverty Line",
       y = "Count of Incidents",
       fill = "Threat Level") + 
  theme(theme(legend.position = 'right'))
poverty_plot
```

### Plot 2

```{r}
#| label: Q1-plot2
#| fig-width: 9
#| fig-asp: 0.8

# Plotting for Educational Bracket
education_plot <- ggplot(analysis_data, aes(x = edu_bracket, fill = threat_level)) +
  geom_bar(position = "identity", width = 0.5) +
  scale_fill_brewer(palette = 'Set3') + 
  theme_minimal() +
  labs(title = "Distribution of Threat Levels by High School Degree Bracket",
       x = "Percentage of Population having High School Degree",
       y = "Count of Incidents",
       fill = "Threat Level") + 
  theme(theme(legend.position = 'right'))

education_plot


# # Combine the plots with a single shared legend on the right
# combined_plot <- poverty_plot / education_plot + 
#   plot_layout(guides = 'collect') + # Collects and deduplicates the guides
#   theme(legend.position = 'right') # Moves the legend to the right
# 
# # Print the combined plot
# print(combined_plot)
```

### Plot 2a

```{r}
#| label: Q1-plot2a
#| message: false

# Calculate the populations of each population for each city
supp_stat <- na.omit(supp_data)
supp_stat <- supp_stat |>
  mutate(
    white_pop <- White * Population / 100,
    black_pop <- Black * Population / 100,
    native_pop <- Native * Population / 100,
    asian_pop <- Asian * Population / 100,
    hispanic_pop <- Hispanic * Population / 100
  )

# Select specific columns of the supplementary data
supp_stat <- supp_stat[,c(1, 2, 4, 15:19)]
colnames(supp_stat) <- c("State", "City", "Median",
                         "White", "Black", "Native", "Asian", "Hispanic")

# Select specific columns of the fatality data
fatality_subset <- fatality[,8:10]
colnames(fatality_subset) <- c("Race", "City", "State")

# Merge dataset and remove rows with NAs
merged_data <- left_join(fatality_subset, supp_stat,
                         by = c("State", "City"))
merged_data <- na.omit(merged_data)

# Acquire counts of race:
# Asian = 23, Black = 409, Hispanic = 301, Native American = 13, Other = 17,
# Unknown = 92, White = 466
race_count <- as.data.frame(summary(as.factor(merged_data$Race)))

# Refactor levels according to the total counts
merged_data$Race <- factor(merged_data$Race,
                           levels = c("Unknown",
                                      "Other",
                                      "Native American",
                                      "Asian",
                                      "Hispanic",
                                      "Black",
                                      "White"))

# Generate the density ridge plot (smallest count at the bottom)
ggplot(merged_data, aes(x = Median, y = Race)) +
  geom_density_ridges() +
  scale_x_continuous(expand = c(0, 0),
                    labels = label_dollar(scale = 1e-3, suffix = "K")) +
  coord_cartesian(clip = "off") +
  geom_text(aes(x = 125000, y = 1.2, label = "13")) +
  geom_text(aes(x = 125000, y = 2.2, label = "17")) +
  geom_text(aes(x = 125000, y = 3.2, label = "23")) +
  geom_text(aes(x = 125000, y = 4.2, label = "92")) +
  geom_text(aes(x = 125000, y = 5.2, label = "301")) +
  geom_text(aes(x = 125000, y = 6.2, label = "409")) +
  geom_text(aes(x = 125000, y = 7.2, label = "466")) +
  labs(title = "Density Plots of Police Shootings",
       subtitle = "Ordered by descending counts") +
  xlab("Median Income of City") +
  ylab("Race") +
  theme_minimal()
```

### Plot 2b

```{r}
#| label: Q1-plot2b
#| message: false

# Find the race populations
# White = 135231935, Black = 30170898, Native = 1827873, Asian = 12570851,
# Hispanic = 51034800
race_pop <- merged_data |>
  distinct(State, City, .keep_all = TRUE)
race_total <- as.data.frame(colSums(race_pop[,5:9]))

# Proportion shot for each race:
# Asian: 23/12570851 * 100 = 1.82963e-04
# Black: 409/30170898 * 100 = 1.355611e-03
# Hispanic: 301/51034800 * 100 = 5.897936e-04
# Native: 13/1827873 * 100 = 7.112091e-04
# White: 466/135231935 * 100 = 3.445932e-04

# Refactor levels according to the proportions
merged_data$Race <- factor(merged_data$Race,
                           levels = c("Unknown",
                                      "Other",
                                      "Asian",
                                      "White",
                                      "Hispanic",
                                      "Native American",
                                      "Black"))

# Generate the density ridge plot (smallest proportion at the bottom)
ggplot(merged_data, aes(x = Median, y = Race)) +
  geom_density_ridges() +
  scale_x_continuous(expand = c(0, 0),
                    labels = label_dollar(scale = 1e-3, suffix = "K")) +
  coord_cartesian(clip = "off") +
  geom_text(aes(x = 125000, y = 3.2, label = "0.0002%")) +
  geom_text(aes(x = 125000, y = 4.2, label = "0.0003%")) +
  geom_text(aes(x = 125000, y = 5.2, label = "0.0006%")) +
  geom_text(aes(x = 125000, y = 6.2, label = "0.0007%")) +
  geom_text(aes(x = 125000, y = 7.2, label = "0.0014%")) +
  labs(title = "Density Plots of Police Shootings",
       subtitle = "Ordered by descending proportion within race") +
  xlab("Median Income of City") +
  ylab("Race") +
  theme_minimal()

```

### Discussion

The above visualizations focus on the distribution of shootings across three demographic categories: median income, percent high school graduates, and poverty level. Plot 1 take takes this further by breaking down the shootings by threat level across poverty level and percent high school graduates. Looking further at Plot 1, two major observations can be made: cities with greater than 75% high school graduates and poverty levels between 18-25% experience the most shootings with roughly half of all incidents showing a threat level of "Attack", meaning the shooting officer felt their safety was at risk via the suspect. Additionally, most shootings had a threat level of "Attack" or "Other", and a minority of the shootings are undetermined, meaning most officers recorded a reason for discharing their weapon. These observations suggest that cities with more high school edcuated individuals and a poverty level that is twice the US average will experience more shootings. One explanation for this is very large US cities like New York City and Chicago. These cities have large populations and a large wage gap between class levels, so the high school graduate percentage is supplemented by higher income classes and the poverty level is driven up by lower income classes, and because of the sheer size of these large cities, there are more cases of shootings, even if the rate per count of population is the same as other cities. Additionally, it can be safely assumed that the lower percentages of high school graduate cities are outliers in the dataset.

Plot 2a breaks down these incidents by raw count of victims in each race population, and Plot 2b takes these raw counts and converts them to overall percent of victims per total population of each race. These plots show these representations across the median income of each city where the shooting occured. From these plots, a few insights can be gained. First, most shootings occur in cities where the median income is roughly between \$40k - \$50k per year, with more shootings at the higher end of that range. Second, out of all races in a given city, white people are shot the most, with the highest raw count. However, when compared to the overal population of each race, black are shot the most, at 0.0014% of the black population being shot, the equivalent of 1 in every 7,143 black people being shot by the police. In contrast, white people have a 0.0003% chance of being shot by the police, or 1 in every 333,334 white people. That means that black people are 47 times more likely to be shot by police, a striking statistic. Finally, the last major observation that can be made is that most native Americans are shot in cities where the median income is roughly \$45k per year, based on the large spike at the \$45k mark.

## Question 2

### Description of Analysis

### Plot 1

```{r}
#| label: Q2-plot1-shooting-intensity-state-wise
#| message: false
#| eval: false

# Creating state_abbreviations dataframe
state_abbreviations <- c(
  "Alabama" = "AL", "Alaska" = "AK", 
  "Arizona" = "AZ", "Arkansas" = "AR",
  "California" = "CA", "Colorado" = "CO", 
  "Connecticut" = "CT", "Delaware" = "DE",
  "District of Columbia" = "DC", "Florida" = "FL", 
  "Georgia" = "GA", "Hawaii" = "HI",
  "Idaho" = "ID", "Illinois" = "IL", "Indiana" = "IN", 
  "Iowa" = "IA", "Kansas" = "KS",
  "Kentucky" = "KY", "Louisiana" = "LA", 
  "Maine" = "ME", "Maryland" = "MD", 
  "Massachusetts" = "MA", "Michigan" = "MI", 
  "Minnesota" = "MN", "Mississippi" = "MS", 
  "Missouri" = "MO", "Montana" = "MT",
  "Nebraska" = "NE", "Nevada" = "NV", 
  "New Hampshire" = "NH", "New Jersey" = "NJ", 
  "New Mexico" = "NM", "New York" = "NY", 
  "North Carolina" = "NC", "North Dakota" = "ND", 
  "Ohio" = "OH", "Oklahoma" = "OK",
  "Oregon" = "OR", "Pennsylvania" = "PA", 
  "Rhode Island" = "RI", "South Carolina" = "SC", 
  "South Dakota" = "SD", "Tennessee" = "TN", 
  "Texas" = "TX", "Utah" = "UT", 
  "Vermont" = "VT", "Virginia" = "VA", "Washington" = "WA",
  "West Virginia" = "WV", "Wisconsin" = "WI", "Wyoming" = "WY", "Puerto Rico" = "PR"
)

state_abbreviations_df <- data.frame(STATE = names(state_abbreviations), state = state_abbreviations, row.names = NULL)


# Creating Fatalaties Summaries by Year
fatality_summaries_year <-
  fatality |> 
  mutate(
    year = year(as.Date(fatality$date,format = "%d/%m/%y"))
  ) |>
  group_by(state,year) |>
  summarise(fatalities_count = n() , .groups = "drop")

## Loading State Population dataset
state_pop <- read.csv("data/Population_Estimate_data_Statewise_2010-2023.csv")

## Creating a long format State Population dataframe
state_pop_updated <- 
  merge(state_pop,state_abbreviations_df) |>
  pivot_longer(
    cols = starts_with("POP"),
    names_to = "year",
    values_to = "popuplation"
  ) |> 
  mutate(
    year = case_when(
      year == "POPESTIMATE2010" ~ year(as.Date("01/01/10",format="%d/%m/%y")),
      year == "POPESTIMATE2011" ~ year(as.Date("01/01/11",format="%d/%m/%y")),
      year == "POPESTIMATE2012" ~ year(as.Date("01/01/12",format="%d/%m/%y")),
      year == "POPESTIMATE2013" ~ year(as.Date("01/01/13",format="%d/%m/%y")),
      year == "POPESTIMATE2014" ~ year(as.Date("01/01/14",format="%d/%m/%y")),
      year == "POPESTIMATE2015" ~ year(as.Date("01/01/15",format="%d/%m/%y")),
      year == "POPESTIMATE2016" ~ year(as.Date("01/01/16",format="%d/%m/%y")),
      year == "POPESTIMATE2017" ~ year(as.Date("01/01/17",format="%d/%m/%y")),
      year == "POPESTIMATE2018" ~ year(as.Date("01/01/18",format="%d/%m/%y")),
      year == "POPESTIMATE2019" ~ year(as.Date("01/01/19",format="%d/%m/%y")),
      year == "POPESTIMATE2020" ~ year(as.Date("01/01/20",format="%d/%m/%y")),
      year == "POPESTIMATE2021" ~ year(as.Date("01/01/21",format="%d/%m/%y")),
      year == "POPESTIMATE2022" ~ year(as.Date("01/01/22",format="%d/%m/%y")),
      year == "POPESTIMATE2023" ~ year(as.Date("01/01/23",format="%d/%m/%y")),
    )
  )

# Merging Fatalaties Summaries by Year with State Population
fatalities_population <- merge(fatality_summaries_year,state_pop_updated)


# Creating an individual fatalaties population wise dataset along with shooting intensity column - Year wise
fatalities_population |>
  mutate(
    intensity = (fatalities_count/popuplation)*1000000,
    region = tolower(STATE)
  ) |>
  filter(
    year == 2015
  ) -> fatalities_population_2015

fatalities_population |>
  mutate(
    intensity = (fatalities_count/popuplation)*1000000,
    region = tolower(STATE)
  ) |>
  filter(
    year == 2016
  ) -> fatalities_population_2016

fatalities_population |>
  mutate(
    intensity = (fatalities_count/popuplation)*1000000,
    region = tolower(STATE)
  ) |>
  filter(
    year == 2017
  ) -> fatalities_population_2017

# Loading USA MAP
us_map_data <- map_data("state")


# Loading World Map and Subsetting Alaska
alaska <-
  map_data("world") |>
  filter(
    region == "USA" & (subregion == "Alaska" ) 
  ) |>
  mutate(
    region = tolower(subregion),
    order = max(us_map_data$order) + 1
  ) |>
  filter(
    long < 0
  )

# Creating Year Wise Map data frame from the fatalies dataset 
merge_2015_us <- full_join(us_map_data,subset(fatalities_population_2015,!(fatalities_population_2015$region=="alaska" |
                                                                      fatalities_population_2015$region=="hawaii")))
merge_2015_alaska <- inner_join(alaska,fatalities_population_2015)

merge_2016_us <- full_join(us_map_data,subset(fatalities_population_2016,!(fatalities_population_2016$region=="alaska" |
                                                                             fatalities_population_2016$region=="hawaii")))
merge_2016_alaska <- inner_join(alaska,fatalities_population_2016)

merge_2017_us <- full_join(us_map_data,subset(fatalities_population_2017,!(fatalities_population_2017$region=="alaska" |
                                                                             fatalities_population_2017$region=="hawaii")))
merge_2017_alaska <- inner_join(alaska,fatalities_population_2017)

# Creating District of Columbia Lat Long Manually
dc_row <- data.frame(long = -77.0369,  # Longitude for Washington, D.C.
                     lat = 38.9072,    # Latitude for Washington, D.C.
                     state = "District of Columbia",
                     region = tolower("District of Columbia"))



# Creating Labels data frame to map the labels at the centre of each state with state name and intensity

label_data <- data.frame(long = state.center$x, lat = state.center$y,
                         state = state.name) |>
  mutate(
    region = tolower(state)
  )

label_data <- bind_rows(label_data, dc_row)

# Creating each year intensity information in columns
label_data <- full_join(label_data,fatalities_population_2015, by = "region") |>
  select(long, lat, region, STATE,intensity) |>
  rename(
    intensity_2015 = intensity)

label_data <- full_join(label_data,fatalities_population_2016, by = "region") |>
  select(long, lat, region, STATE.x,intensity_2015, intensity) |>
  rename(
    intensity_2016 = intensity,
    STATE = STATE.x)

label_data <- full_join(label_data,fatalities_population_2017, by = "region") |>
  select(long, lat,region, STATE.x,intensity_2015,intensity_2016, intensity) |>
  rename(
    intensity_2017 = intensity,
    STATE = STATE.x) |>
  mutate(
    intensity_2017_up = intensity_2017*1.75
  )

# Creating Alaka Label information separately
alaska_label <- label_data |>
  filter(
    STATE %in% c("Alaska")
    ) |>
  mutate(
    long = case_when(
      STATE == "Alaska" ~ -150,
      STATE != "Alaska" ~ long
    ),
    lat = case_when(
      STATE == "Alaska" ~ 65,
      STATE != "Alaska" ~ lat
    )
  )

# Removing Alaska from label_data as in above alaksa_label is already created
label_data <-label_data |>
  filter(
    !(STATE %in% c("Hawaii", "Alaska"))
  )

label_data$STATE[label_data$region=="rhode island"] <- "Rhode Island"

## Creating 2015 Shooting Intensity plot for Alaska which will be annotated in usa map

ggplot() +
  geom_polygon(data = merge_2015_alaska,
               aes(x = long, y = lat,group=group), fill = "#e69e91",
               color = "white", linewidth = 0.2) +
  expand_limits(x = merge_2015_alaska$long, y = merge_2015_alaska$lat) +
  geom_label_repel(data = alaska_label, aes(x = long, y = lat, label = paste(STATE,":\n",round(intensity_2015,1))), size = 20) +
  theme_void() +
  theme(legend.position = "none") + 
  coord_cartesian(xlim = c(-180, 0), ylim = c(0, 90)) -> plot1

## Creating 2015 Shooting Intensity plot for USA 
ggplot() +
  geom_polygon(data = merge_2015_us,
           aes(x = long, y = lat, group = group, fill = intensity),
           color = "white", linewidth = 0.2) +
  scale_fill_gradient(low = "#fee5d9", high = "#a50f15", na.value = "grey50",
                      name = "Intensity") +
  geom_label_repel(data = label_data %>% filter(intensity_2015 > 3), aes(x = long, y = lat, label = paste(STATE,":\n",round(intensity_2015,1))), size = 20) +
  expand_limits(x = merge_2015_us$long, y = merge_2015_us$lat) +
  labs(title = "Shooting Intensity by State : 2015",
       subtitle = "Per Million of Population",
       caption = paste("Highlighted states have shooting intensity > 3 : #", length(fatalities_population_2015$intensity[fatalities_population_2015$intensity>3]),
                       "\n Grey states indicate no fatalties in that year")
       ) +
       annotation_custom(ggplotGrob(plot1),xmin = -130, xmax = -70, ymin = 0, ymax = 40) + theme_void() +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(4, "cm"),
    legend.title = element_text(size = 48),
    legend.text = element_text(size = 48),
    plot.title = element_text(hjust = 0.5, size = 96, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 80),
    plot.caption = element_text(size = 40)
    ) + 
  annotate(
    "text",
    x = -80,
    y = 45,
    label = "Top 3 by Shooting Intensity:
    1) Wyoming
    2) New Mexico
    3) Oklahoma",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) + 
  annotate(
    "text",
    x = -70,
    y = 30,
    label = "Top 3 by Total Fatalities:
    1) California
    2) Texas
    3) Florida",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) -> plot_2015_map



## Creating 2016 Shooting Intensity plot for Alaska which will be annotated in usa map
ggplot() +
  geom_polygon(data = merge_2016_alaska,
               aes(x = long, y = lat,group=group), fill = "#a50f15",
               color = "white", size = 0.2) +
  expand_limits(x = merge_2016_alaska$long, y = merge_2016_alaska$lat) +
  geom_label_repel(data = alaska_label, aes(x = long, y = lat, label = paste(STATE,":\n",round(intensity_2016,1))), size = 20) +
  theme_void() +
  theme(legend.position = "none") + 
  coord_cartesian(xlim = c(-180, 0), ylim = c(0, 90)) -> plot2


## Creating 2016 Shooting Intensity plot for USA 
ggplot() +
  geom_polygon(data = merge_2016_us,
               aes(x = long, y = lat, group = group, fill = intensity),
               color = "white", size = 0.2) +
  scale_fill_gradient(low = "#fee5d9", high = "#a50f15", na.value = "grey50",
                      name = "Intensity") +
  geom_label_repel(data = label_data %>% filter(intensity_2016 > 3), aes(x = long, y = lat, label = paste(STATE,":\n",round(intensity_2016,1))), size = 20) +
  expand_limits(x = merge_2016_us$long, y = merge_2016_us$lat) +
  labs(title = "Shooting Intensity by State : 2016",
       subtitle = "Per Million of Population",
       caption = paste("Highlighted states have shooting intensity > 3 : #", length(fatalities_population_2016$intensity[fatalities_population_2016$intensity>3]),
                       "\n Grey states indicate no fatalties in that year")
       ) +
  annotation_custom(ggplotGrob(plot2),xmin = -130, xmax = -70, ymin = 0, ymax = 40) + theme_void() +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(4, "cm"),
    legend.title = element_text(size = 48),
    legend.text = element_text(size = 48),
    plot.title = element_text(hjust = 0.5, size = 96, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 80),
    plot.caption = element_text(size = 40)
  ) + 
  annotate(
    "text",
    x = -80,
    y = 45,
    label = "Top 3 by Shooting Intensity:
    1) New Mexico
    2) Alaska
    3) District of Columbia",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) + 
  annotate(
    "text",
    x = -75,
    y = 30,
    label = "Top 3 by Total Fatalities:
    1) California
    2) Texas
    3) Florida",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) -> plot_2016_map




## Creating 2017 Shooting Intensity plot for Alaska which will be annotated in usa map

ggplot() +
  geom_polygon(data = merge_2017_alaska,
               aes(x = long, y = lat,group=group), fill = "#a50f15",
               color = "white", size = 0.2) +
  expand_limits(x = merge_2017_alaska$long, y = merge_2017_alaska$lat) +
  geom_label_repel(data = alaska_label, aes(x = long, y = lat, label = paste(STATE,":\n",round(intensity_2017_up,1))), size = 20) +
  theme_void() +
  theme(legend.position = "none") + 
  coord_cartesian(xlim = c(-180, 0), ylim = c(0, 90)) -> plot3

## Creating 2017 Shooting Intensity plot for USA 

ggplot() +
  geom_polygon(data = merge_2017_us,
               aes(x = long, y = lat, group = group, fill = intensity),
               color = "white", size = 0.2) +
  scale_fill_gradient(low = "#fee5d9", high = "#a50f15", na.value = "grey50",
                      name = "Intensity") +
  geom_label_repel(data = label_data %>% filter(intensity_2017_up > 3), aes(x = long, y = lat, label = paste(STATE,"\n",round(intensity_2017_up,1))), size = 20) +
  expand_limits(x = merge_2017_us$long, y = merge_2017_us$lat) +
  labs(title = "Shooting Intensity by State : 2017",
       subtitle = "Per Million of Population",
       caption = paste("Highlighted states have shooting intensity > 3 : #", length(fatalities_population_2017$intensity[fatalities_population_2017$intensity>1.75]),
                       "\n data scaled by 1.75 times, original data was till July 2017",
                       "\n Grey states indicate no fatalties in that year")
  ) +
  annotation_custom(ggplotGrob(plot3),xmin = -130, xmax = -70, ymin = 0, ymax = 40) + theme_void() +
  theme(
    legend.position = "bottom",
    legend.key.size = unit(4, "cm"),
    legend.title = element_text(size = 48),
    legend.text = element_text(size = 48),
    plot.title = element_text(hjust = 0.5, size = 96, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 80),
    plot.caption = element_text(size = 40)
  ) + 
  annotate(
    "text",
    x = -80,
    y = 45,
    label = "Top 3 by Shooting Intensity:
    1) Maine
    2) Alaska
    3) Oklahoma",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) + 
  annotate(
    "text",
    x = -75,
    y = 30,
    label = "Top 3 by Total Fatalities:
    1) California
    2) Texas
    3) Florida",
    size = 20,
    fontface = "italic",
    color = "#a50f15",
    vjust = 0
  ) -> plot_2017_map

# Creating an animation for above map plots with better resolution
animation::saveGIF(
  expr = {
    plot(plot_2015_map)
    plot(plot_2016_map)
    plot(plot_2017_map)
  },
  movie.name = "shooting_intensity.gif",
  interval = 4,
  ani.width = 4800,
  ani.height = 3000,
  ani.dev = "png",
  ani.type = "cairo",
  res = 200,
  ani.x = "in",
  ani.y = "in",
  ani.unit = "in",
  ani.bg = "white",
  ani.fps = 3
  )

```

![](images/shooting_intensity.gif){fig-align="center"}

### Plot 2

```{r}
#| label: Q2-plot2
#| message: false
#| eval: false


fatality <- read.csv("data/PoliceKillingsUS.csv", na.strings = "")
median_income <- read.csv("data/MedianHouseholdIncome2015.csv")
poverty_perc <- read.csv("data/PercentagePeopleBelowPovertyLevel.csv")
hs_perc <- read.csv("data/PercentOver25CompletedHighSchool.csv")
race_perc <- read.csv("data/ShareRaceByCity.csv")
city_pop <- read.csv("data/us-cities-top-1k-multi-year.csv")
state_pop <- read.csv("data/Population_Estimate_data_Statewise_2010-2023.csv")


state_abbreviations <- c(
  "Alabama" = "AL", "Alaska" = "AK", "Arizona" = "AZ", "Arkansas" = "AR",
  "California" = "CA", "Colorado" = "CO", "Connecticut" = "CT", "Delaware" = "DE",
  "District of Columbia" = "DC", "Florida" = "FL", "Georgia" = "GA", "Hawaii" = "HI",
  "Idaho" = "ID", "Illinois" = "IL", "Indiana" = "IN", "Iowa" = "IA", "Kansas" = "KS",
  "Kentucky" = "KY", "Louisiana" = "LA", "Maine" = "ME", "Maryland" = "MD", "Massachusetts" = "MA",
  "Michigan" = "MI", "Minnesota" = "MN", "Mississippi" = "MS", "Missouri" = "MO", "Montana" = "MT",
  "Nebraska" = "NE", "Nevada" = "NV", "New Hampshire" = "NH", "New Jersey" = "NJ", "New Mexico" = "NM",
  "New York" = "NY", "North Carolina" = "NC", "North Dakota" = "ND", "Ohio" = "OH", "Oklahoma" = "OK",
  "Oregon" = "OR", "Pennsylvania" = "PA", "Rhode Island" = "RI", "South Carolina" = "SC", "South Dakota" = "SD",
  "Tennessee" = "TN", "Texas" = "TX", "Utah" = "UT", "Vermont" = "VT", "Virginia" = "VA", "Washington" = "WA",
  "West Virginia" = "WV", "Wisconsin" = "WI", "Wyoming" = "WY", "Puerto Rico" = "PR"
)

state_abbreviations_df <- data.frame(STATE = names(state_abbreviations), state = state_abbreviations, row.names = NULL)


fatality_summaries_year <-
  fatality |> 
  mutate(
    year = year(as.Date(fatality$date,format = "%d/%m/%y"))
  ) |>
  group_by(state,year) |>
  summarise(fatalities_count = n() , .groups = "drop")


state_pop_updated <- 
  merge(state_pop,state_abbreviations_df) |>
  pivot_longer(
    cols = starts_with("POP"),
    names_to = "year",
    values_to = "popuplation"
  ) |> 
  mutate(
    year = case_when(
      year == "POPESTIMATE2010" ~ year(as.Date("01/01/10",format="%d/%m/%y")),
      year == "POPESTIMATE2011" ~ year(as.Date("01/01/11",format="%d/%m/%y")),
      year == "POPESTIMATE2012" ~ year(as.Date("01/01/12",format="%d/%m/%y")),
      year == "POPESTIMATE2013" ~ year(as.Date("01/01/13",format="%d/%m/%y")),
      year == "POPESTIMATE2014" ~ year(as.Date("01/01/14",format="%d/%m/%y")),
      year == "POPESTIMATE2015" ~ year(as.Date("01/01/15",format="%d/%m/%y")),
      year == "POPESTIMATE2016" ~ year(as.Date("01/01/16",format="%d/%m/%y")),
      year == "POPESTIMATE2017" ~ year(as.Date("01/01/17",format="%d/%m/%y")),
      year == "POPESTIMATE2018" ~ year(as.Date("01/01/18",format="%d/%m/%y")),
      year == "POPESTIMATE2019" ~ year(as.Date("01/01/19",format="%d/%m/%y")),
      year == "POPESTIMATE2020" ~ year(as.Date("01/01/20",format="%d/%m/%y")),
      year == "POPESTIMATE2021" ~ year(as.Date("01/01/21",format="%d/%m/%y")),
      year == "POPESTIMATE2022" ~ year(as.Date("01/01/22",format="%d/%m/%y")),
      year == "POPESTIMATE2023" ~ year(as.Date("01/01/23",format="%d/%m/%y")),
    )
  )

fatalities_population <- merge(fatality_summaries_year,state_pop_updated)



city_fatality_summaries_year <-
  fatality |> 
  mutate(
    year = year(as.Date(fatality$date,format = "%d/%m/%y"))
  ) |>
  group_by(state,city,year) |>
  summarise(fatalities_count = n() , .groups = "drop")

city_fatality_summaries_year1 <- subset(city_fatality_summaries_year, city_fatality_summaries_year$year == 2015)

city_fatality_summaries_year2 <- subset(city_fatality_summaries_year, city_fatality_summaries_year$year == 2016)

fatality_summaries_year <- rbind(city_fatality_summaries_year1,city_fatality_summaries_year2)

rm(city_fatality_summaries_year1,city_fatality_summaries_year2)

city_fatalities_population <- merge(city_fatality_summaries_year,city_pop,by.x = c("city","year"),by.y = c("City","year"))

city_fatalities_population |>
  mutate(
    intensity = (fatalities_count/Population)*1000000,
    region = tolower(State)
  ) |>
  filter(
    year == 2015,
    lon > -150
  ) |>
  arrange(desc(intensity)) |> 
  distinct(city, .keep_all = TRUE) -> city_fatalities_population_2015

city_fatalities_population |>
  mutate(
    intensity = (fatalities_count/Population)*1000000,
    region = tolower(State)
  ) |>
  filter(
    year == 2016
  ) |> 
  arrange(desc(intensity)) |> 
  distinct(city, .keep_all = TRUE) -> city_fatalities_population_2016

fatalities_population |>
  mutate(
    intensity = (fatalities_count/popuplation)*1000000,
    region = tolower(STATE)
  ) |>
  filter(
    year == 2015
  ) -> fatalities_population_2015

fatalities_population |>
  mutate(
    intensity = (fatalities_count/popuplation)*1000000,
    region = tolower(STATE)
  ) |>
  filter(
    year == 2016
  ) -> fatalities_population_2016


us_map_data <- map_data("state")



alaska <-
  map_data("world") |>
  filter(
    region == "USA" & (subregion == "Alaska" ) 
  ) |>
  mutate(
    region = tolower(subregion),
    order = max(us_map_data$order) + 1
  ) |>
  filter(
    long < 0
  )


merge_2015_us <- full_join(us_map_data,subset(fatalities_population_2015,!(fatalities_population_2015$region=="alaska" |
                                                                             fatalities_population_2015$region=="hawaii")))
merge_2015_alaska <- inner_join(alaska,fatalities_population_2015)

merge_2016_us <- full_join(us_map_data,subset(fatalities_population_2016,!(fatalities_population_2016$region=="alaska" |
                                                                             fatalities_population_2016$region=="hawaii")))
merge_2016_alaska <- inner_join(alaska,fatalities_population_2016)


ggplot() +
  geom_polygon(data = merge_2015_alaska,
               aes(x = long, y = lat,group=group), fill = "#e69e91",
               color = "white", size = 0.2) +
  expand_limits(x = merge_2015_alaska$long, y = merge_2015_alaska$lat) +
  theme_void() +
  theme(legend.position = "none") + 
  coord_cartesian(xlim = c(-180, 0), ylim = c(0, 90)) +
  geom_point(data = subset(city_fatalities_population_2015,city_fatalities_population_2015$region=="alaska"),aes(x = lon,y=lat), color = "darkred")-> plot1_city

ggplot() +
  geom_polygon(data = merge_2015_us,
               aes(x = long, y = lat, group = group, fill = intensity),
               color = "white", size = 0.2) +
  scale_fill_gradient(low = "#fee5d9", high = "#a50f15", na.value = "grey50",
                      name = "State") +
  expand_limits(x = merge_2015_us$long, y = merge_2015_us$lat) +
  annotation_custom(ggplotGrob(plot1_city),xmin = -130, xmax = -70, ymin = 0, ymax = 40) + theme_void() +
  geom_point(data = subset(city_fatalities_population_2015,city_fatalities_population_2015$lon>-140),aes(x = lon,y=lat, size = intensity),
                                                                                                         color = "#8B0020") +
  geom_label_repel(data = city_fatalities_population_2015 %>% filter(intensity > 28), 
                   aes(x = lon, y = lat, label = paste(city,"\n",round(intensity,1))), 
                   #color = "#56007C",
                   color = "#000000",
                   nudge_x = ifelse(city_fatalities_population_2015$city == "Oakland", -2, -0.5),
                   nudge_y = ifelse(city_fatalities_population_2015$city == "Oakland", -1, -0.5),
                   size = 3.5, 
                   fill = "transparent") +
  guides(size = guide_legend(override.aes = list(fill = "transparent"))) + 
  labs(title = "Shooting Intensity by City : 2015",
       subtitle = "Per Million of Population",
      size = "City",
      caption = "Cities labels are of shooting intensity > 28 \n Grey highlighted states have NO fatalities"
  ) +
  theme(
    legend.text = element_text(size = 9, color = "black"), 
    #legend.key.size = unit(4, "cm"),
    legend.title = element_text(size = 12),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    plot.caption = element_text(size = 10)
  ) -> map_2015_city
  



ggplot() +
  geom_polygon(data = merge_2016_alaska,
               aes(x = long, y = lat,group=group), fill = "#e69e91",
               color = "white", size = 0.2) +
  expand_limits(x = merge_2016_alaska$long, y = merge_2016_alaska$lat) +
  theme_void() +
  theme(legend.position = "none") + 
  coord_cartesian(xlim = c(-180, 0), ylim = c(0, 90)) +
  geom_point(data = subset(city_fatalities_population_2016,city_fatalities_population_2016$region=="alaska"),aes(x = lon,y=lat), color = "darkred")-> plot2_city

ggplot() +
  geom_polygon(data = merge_2016_us,
               aes(x = long, y = lat, group = group, fill = intensity),
               color = "white", size = 0.2) +
  scale_fill_gradient(low = "#fee5d9", high = "#a50f15", na.value = "grey50",
                      name = "State") +
  expand_limits(x = merge_2016_us$long, y = merge_2016_us$lat) +
  annotation_custom(ggplotGrob(plot2_city),xmin = -130, xmax = -70, ymin = 0, ymax = 40) + theme_void() +
  geom_point(data = subset(city_fatalities_population_2016,city_fatalities_population_2016$lon>-140),aes(x = lon,y=lat, size = intensity),
             color = "#8B0020") +
  geom_label_repel(data = city_fatalities_population_2016 %>% filter(intensity > 28), 
                   aes(x = lon, y = lat, label = paste(city,"\n",round(intensity,1))), 
                   #color = "#56007C",
                   color = "#000000",
                   #nudge_x = ifelse(city_fatalities_population_2016$city == "Oakland", -2, -0.5),
                   #nudge_y = ifelse(city_fatalities_population_2016$city == "Oakland", -1, -0.5),
                   size = 3.5, 
                   fill = "transparent") +
  guides(size = guide_legend(override.aes = list(fill = "transparent"))) + 
  labs(title = "Shooting Intensity by City : 2016",
       subtitle = "Per Million of Population",
       size = "City",
       caption = "Cities labels are of shooting intensity > 28 \n Grey highlighted states have NO fatalities"
  ) +
  theme(
    legend.text = element_text(size = 9, color = "black"), 
    #legend.key.size = unit(4, "cm"),
    legend.title = element_text(size = 12),
    plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
    plot.subtitle = element_text(hjust = 0.5, size = 12),
    plot.caption = element_text(size = 10)
  ) -> map_2016_city


library(animation)

# explicit
animation::saveGIF(
  expr = {
    plot(map_2015_city)
    plot(map_2016_city)
  },
  movie.name = "shooting_intensity_city.gif",
  interval = 4,
  ani.width = 1200,
  ani.height = 700,
  ani.dev = "png",
  ani.type = "cairo",
  res = 300,
  ani.x = "in",
  ani.y = "in",
  ani.unit = "in",
  ani.bg = "white",
  ani.fps = 3
)




  

```

![](images/shooting_intensity_city.gif){fig-align="center"}

**Plot 3**

```{r}
#| label: Q.2 plot 3

library(utils)
library(dplyr)
library(tidyr)

fatality <- read.csv("data/PoliceKillingsUS.csv", na.strings = "")
race_perc <- read.csv("data/ShareRaceByCity.csv")
state_pop <- read.csv("data/Population_Estimate_data_Statewise_2010-2023.csv")
fatality$year <- format(as.Date(fatality$date, format = "%d/%m/%y"), "%Y")
# 
# View(fatality)
# View(race_perc)
# View(state_pop)
# str(state_pop) 
# glimpse(fatality)


# Group by year, state, and race, then count occurrences
race_count <- fatality %>%
  group_by(year, state, race) %>%
  summarise(count = n()) %>%
  ungroup()

# Spread the 'race' column to create individual columns for each race
race_count <- race_count %>%
  spread(key = race, value = count, fill = 0)

# Add a column for the total count of races in each state and year
race_count <- race_count %>%
  mutate(Total = rowSums(select(., -c(year, state)), na.rm = TRUE))

# Arrange the data by year and state
race_count <- race_count %>%
  arrange(year, state)

# View the resulting dataframe
View(race_count)
```

```{r}
#| label: data-wrangling for race_perc

race_perc <- read.csv("data/ShareRaceByCity.csv")
# Remove the 'City' column from race_perc dataframe
race_perc <- race_perc %>%
  select(-City)

# Convert columns to numeric
race_perc$share_white <- as.numeric(race_perc$share_white)
race_perc$share_black <- as.numeric(race_perc$share_black)
race_perc$share_native_american <- as.numeric(race_perc$share_native_american)
race_perc$share_asian <- as.numeric(race_perc$share_asian)
race_perc$share_hispanic <- as.numeric(race_perc$share_hispanic)

# Add a column for the sum of all race percentages
race_perc$sum_race_percentages <- rowSums(race_perc[, c("share_white", "share_black", "share_native_american", "share_asian", "share_hispanic")])


# # View the structure of the updated dataframe
# str(race_perc)
# 
# # View the first few rows of the updated dataframe
# head(race_perc)


# View the structure of the dataframe after conversion
View(race_perc)



# Assuming race_perc is already loaded as a dataframe
race_perc <- race_perc %>%
  group_by(Geographic.area) %>%
  summarise(
    share_white = mean(share_white, na.rm = TRUE),
    share_black = mean(share_black, na.rm = TRUE),
    share_native_american = mean(share_native_american, na.rm = TRUE),
    share_asian = mean(share_asian, na.rm = TRUE),
    share_hispanic = mean(share_hispanic, na.rm = TRUE),
    sum_race_percentages=mean(sum_race_percentages,na.rm = TRUE)
  )

View(race_perc)

# Normalize race percentages
race_perc <- race_perc %>%
  mutate(
    share_white = share_white / sum_race_percentages,
    share_black = share_black / sum_race_percentages,
    share_native_american = share_native_american / sum_race_percentages,
    share_asian = share_asian / sum_race_percentages,
    share_hispanic = share_hispanic / sum_race_percentages
  )

# Recalculate sum_race_percentages
race_perc$sum_race_percentages <- rowSums(select(race_perc, starts_with("share_")))
 
View(race_perc)



```

```{r}
#| label: population_data_update

# Selecting desired columns from state_pop
state_pop_subset <- state_pop[, c("STATE", "POPESTIMATE2015", "POPESTIMATE2016", "POPESTIMATE2017")]

# # View the structure of the new dataframe
# str(state_pop_subset)
# 
# # View the first few rows of the new dataframe
# head(state_pop_subset)

# Reshape the dataframe to have Year, State, and Population columns
state_pop_long <- state_pop_subset %>%
  pivot_longer(cols = c("POPESTIMATE2015", "POPESTIMATE2016", "POPESTIMATE2017"),
               names_to = "Year",
               values_to = "Population")

# Remove "POPESTIMATE" from the Year column
state_pop_long <- state_pop_long %>%
  mutate(Year = str_remove(Year, "POPESTIMATE"))

# Convert Year column to numeric for sorting
state_pop_long$Year <- as.numeric(state_pop_long$Year)

# Sort the dataframe by Year in ascending order
state_pop_long <- state_pop_long %>%
  arrange(Year)

# View the sorted dataframe
str(state_pop_long)
View(state_pop_long)
```

```{r}
#| label: merging two dataframe 

# Define a mapping of state names to state codes
state_mapping <- c(
  "Alabama" = "AL", "Alaska" = "AK", "Arizona" = "AZ", "Arkansas" = "AR",
  "California" = "CA", "Colorado" = "CO", "Connecticut" = "CT", "Delaware" = "DE",
  "District of Columbia" = "DC", "Florida" = "FL", "Georgia" = "GA", "Hawaii" = "HI",
  "Idaho" = "ID", "Illinois" = "IL", "Indiana" = "IN", "Iowa" = "IA",
  "Kansas" = "KS", "Kentucky" = "KY", "Louisiana" = "LA", "Maine" = "ME",
  "Maryland" = "MD", "Massachusetts" = "MA", "Michigan" = "MI", "Minnesota" = "MN",
  "Mississippi" = "MS", "Missouri" = "MO", "Montana" = "MT", "Nebraska" = "NE",
  "Nevada" = "NV", "New Hampshire" = "NH", "New Jersey" = "NJ", "New Mexico" = "NM",
  "New York" = "NY", "North Carolina" = "NC", "North Dakota" = "ND", "Ohio" = "OH",
  "Oklahoma" = "OK", "Oregon" = "OR", "Pennsylvania" = "PA", "Rhode Island" = "RI",
  "South Carolina" = "SC", "South Dakota" = "SD", "Tennessee" = "TN", "Texas" = "TX",
  "Utah" = "UT", "Vermont" = "VT", "Virginia" = "VA", "Washington" = "WA",
  "West Virginia" = "WV", "Wisconsin" = "WI", "Wyoming" = "WY", "Puerto Rico" = "PR"
)

# Add STATE CODE column to state_pop dataframe
state_pop_long <- mutate(state_pop_long, STATE_CODE = state_mapping[STATE])

# Rearrange columns with STATE CODE after STATE
state_pop_long <- state_pop_long %>%
  select(STATE, STATE_CODE, everything())

# View the updated dataframe

View(state_pop_long)

# str(race_perc)


# Merge race_perc and state_pop_long dataframes based on state information
merged_data <- merge(race_perc, state_pop_long, by.x = "Geographic.area", by.y = "STATE_CODE")
# 
# Convert race percentage columns to numeric
percentage_cols <- c("share_white", "share_black", "share_native_american", "share_asian", "share_hispanic")
merged_data[percentage_cols] <- lapply(merged_data[percentage_cols], as.numeric)

View(merged_data)
```

```{r}

merged_data <- merged_data %>%
  mutate(
    white_population = share_white * Population,
    black_population = share_black * Population,
    native_american_population = share_native_american * Population,
    asian_population = share_asian * Population,
    hispanic_population = share_hispanic * Population
  )

View(merged_data)

# Select the desired columns
merged_data <- merged_data %>%
  select(Geographic.area, Year, Population, white_population, black_population, 
         native_american_population, asian_population, hispanic_population)

# View the resulting dataframe
str(merged_data)
View(merged_data)


# # Group data by STATE and Year, and calculate sum of racial populations and averages
# grouped_merged_data <- merged_data %>%
#   mutate(
#     white_population = ifelse(white_population == 0, NA, white_population),
#     black_population = ifelse(black_population == 0, NA, black_population),
#     native_american_population = ifelse(native_american_population == 0, NA, native_american_population),
#     asian_population = ifelse(asian_population == 0, NA, asian_population),
#     hispanic_population = ifelse(hispanic_population == 0, NA, hispanic_population)
#   ) %>%
#   group_by(Geographic.area, Year) %>%
#   summarise(
#     sum_white_population = sum(white_population, na.rm = TRUE),
#     sum_black_population = sum(black_population, na.rm = TRUE),
#     sum_native_american_population = sum(native_american_population, na.rm = TRUE),
#     sum_asian_population = sum(asian_population, na.rm = TRUE),
#     sum_hispanic_population = sum(hispanic_population, na.rm = TRUE), 
#     sum_race_population = sum(Population)
#   )
# 
# # View the resulting dataframe
# head(grouped_merged_data)
# 
# 
# # View the resulting dataframe
# View(grouped_merged_data)
# str(grouped_merged_data)
```

```{r}
#| label: Fatalities_merging

fatality <- read.csv("data/PoliceKillingsUS.csv", na.strings = "")
fatality$year <- format(as.Date(fatality$date, format = "%d/%m/%y"), "%Y")
# Keep only the required columns
fatality <- fatality %>%
  select(race,state,year)

str(fatality)
View(fatality)


# Pivot the data wider
fatality_spread <- fatality %>%
  pivot_wider(
    id_cols = c(state, year),
    names_from = race,
    values_from = race,
    values_fn = length,
    values_fill = 0
  )

# Rename the racial columns
fatality_spread <- fatality_spread %>%
  rename(
    share_white = W,
    share_black = B,
    share_native_american = 'NA',
    share_asian = A,
    share_hispanic = H
   )

# Merge "N" and "O" columns into "Other" column
fatality_spread <- fatality_spread %>%
  mutate(Other = N + O) %>%
  select(-N, -O)

# View the modified dataframe
head(fatality_spread)

# View the first few rows of the spread dataframe
View(fatality_spread)
str(fatality_spread)
```

```{r}
#| label: sada

library(dplyr)

# Rename 'Geographic.area' to 'state' in grouped_merged_data for consistency
merged_data <- merged_data %>%
  rename(state = Geographic.area)

# Convert Year column in grouped_merged_data to character
merged_data <- merged_data %>%
  mutate(Year = as.character(Year))

# Perform left join
Final_racial_data <- left_join(merged_data, fatality_spread, by = c("state" = "state", "Year" = "year"))

# View the resulting dataframe
View(Final_racial_data)
str(Final_racial_data)

```

```{r}
#| label: intensity


# Calculate racial intensity for each racial group
Final_racial_data <- Final_racial_data %>%
  mutate(
    white_intensity = (share_white / white_population) * 10^6,
    black_intensity = (share_black / black_population) * 10^6,
    native_american_intensity = (share_native_american / native_american_population) * 10^6,
    asian_intensity = (share_asian / asian_population) * 10^6,
    hispanic_intensity = (share_hispanic / hispanic_population) * 10^6
  )

# View the resulting dataframe
head(Final_racial_data)
View(Final_racial_data)
```

\

### Discussion
